
Have file for main agent:
- Communication style / vibe style / Behavior
- User knowledge folder
  - Life (past knowledge of the user life)
  - Habit / hobbit
  - preference
- ... 



Eye tracker to click on things with saying click, execute action etc...


Have an intiating phase on first setup where the human have to answer the initial question / phase concept planning
- link the human to the app / ai


Being able to setup a hotkey that trigger something like an action in our app
  - Record voice and submit / paste text (from speach to text model) in the input where the cursor is
    - Hotkey record then same hotkey cut the feed and hit a custom services with the voice recording to the agent, back to us with a text result